{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('CLIP-dissect') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import similarity\n",
    "import utils\n",
    "import data_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron_accuracy import get_actual_labels, neuron_accuracy\n",
    "from clip_dissect_pipeline import dissect_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"FER2013\"\n",
    "class_names = os.listdir(dataset_path+\"/train\")\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = []\n",
    "for file_name in glob.glob(dataset_path+'/train/*/*'):\n",
    "    emotion = file_name.split('/')[-2]\n",
    "    if emotion not in emotions:\n",
    "        img = cv2.imread(file_name)\n",
    "    emotions.append(emotion)\n",
    "    \n",
    "emotions = []\n",
    "for file_name in glob.glob(dataset_path+'/test/*/*'):\n",
    "    emotion = file_name.split('/')[-2]\n",
    "    if emotion not in emotions:\n",
    "        img = cv2.imread(file_name)\n",
    "    emotions.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Resize((48,48))])\n",
    "\n",
    "train_dataset = ImageFolder(dataset_path+'/train',transform)\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=100*6)\n",
    "#creating val data loaders\n",
    "val_dataset = ImageFolder(dataset_path+'/test',transform)\n",
    "val_loader = DataLoader(dataset=val_dataset,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to change this part\n",
    "d_probe = train_dataset\n",
    "concept_set = class_names\n",
    "similarity_fn = similarity.soft_wpmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 48, 48])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "model_path = 'face_emotion_deep_emotion.pth'\n",
    "target_model = models.Deep_Emotion().to('cuda')\n",
    "target_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_probe = 'FER2013'\n",
    "concept_set = 'CLIP-dissect/data/emotions.txt' # concept set needs to be path to .txt file\n",
    "similarity_fn = similarity.soft_wpmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_emotions, neuron_image_indices = dissect_pipeline(d_probe,concept_set, similarity_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_accuracy(neuron_image_indices, predicted_emotions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facebase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
